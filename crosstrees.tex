
%%%%%%%%%%%%%%%%%%%%%%% file typeinst.tex %%%%%%%%%%%%%%%%%%%%%%%%%
%
% This  is the LaTeX source for the instructions to authors using
% the LaTeX document class 'llncs.cls' for contributions to
% the Lecture Notes in Computer Sciences series.
% http://www.springer.com/lncs       Springer Heidelberg 2006/05/04
%
% It may be used as a template for your own input - copy it
% to a new file with a new name and use it as the basis
% for your article.
%
% NB: the document class 'llncs' has its own and detailed documentation, see
% ftp://ftp.springer.de/data/pubftp/pub/tex/latex/llncs/latex2e/llncsdoc.pdf
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\documentclass[runningheads]{llncs}

\usepackage{amssymb}
\usepackage{cite}
\setcounter{tocdepth}{3}
\usepackage{graphicx}

\usepackage{url}
\urldef{\mailsa}\path|{alfred.hofmann,ursula.barth,ingrid.beyer,natalie.brecht,|
\urldef{\mailsb}\path|christine.guenther,frank.holzwarth,piamaria.karbach,|
\urldef{\mailsc}\path|anna.kramer,erika.siebert-cole,lncs}@springer.com|
\newcommand{\keywords}[1]{\par\addvspace\baselineskip
\noindent\keywordname\enspace\ignorespaces#1}

\newenvironment{myepigraph}
  {\par\hfill\itshape
   \begin{tabular}{@{}r@{}}} % 2em from the right margin
  {\end{tabular}\par\medskip}


\newcommand{\bi}{\begin{itemize}}
\newcommand{\ei}{\end{itemize}}
\newcommand{\be}{\begin{enumerate}}
\newcommand{\ee}{\end{enumerate}}

\newcommand{\fig}[1]{Figure~\ref{fig:#1}}
\newcommand{\eq}[1]{Equation~\ref{eq:#1}}
\newcommand{\tion}[1]{\S\ref{sec:#1}}


\usepackage[small,compact]{titlesec}



\usepackage{times}
\def\baselinestretch{0.95}


 \usepackage[font={small}]{caption, subfig}
 \renewcommand{\figurename}{Fig.}
 \renewcommand{\tablename}{Tab.}
\usepackage{enumitem}
\setlength{\abovecaptionskip}{1ex}
 \setlength{\belowcaptionskip}{1ex}
 \setlength{\floatsep}{1ex}
 \setlength{\textfloatsep}{1ex}
\setlist{nosep}

%\usepackage{biblatex}
%\renewcommand*{\bibfont}{\footnotesize}
%\usepackage[sort&compress]{natbib}  
 \newcommand{\bibfont}{\tiny}
% \setlength{\bibsep}{0ex}
%\renewcommand\section{\@startsection{section}{1}{\z@}{-10\p@ \@plus -4\p@ \@minus -4\p@}{5\p@ \@plus 4\p@ \@minus 4\p@}{\normalfont\large\bfseries\boldmath\rightskip=\z@ \@plus 8em\pretolerance=10000 }}


\begin{document}


\mainmatter  % start of an individual contribution

% first the title is needed
\title{Finding Explanations for Multi-Objective Optimization
(in Near-Linear Time)}

% a short form should be given in case it is too long for the running head
\titlerunning{SSBSE'15}

% the name(s) of the author(s) follow(s) next
%
% NB: Chinese authors should write their first names(s) in front of
% their surnames. This ensures that the names appear correctly in
% the running heads and the author index.
%
\author{Authors suppressed for blind review}

%<nalekkalapudi@mix.wvu.edu>Tim Menzies%
%%\and Ursula Barth\and Ingrid Beyer\and Natalie Brecht\and\\
%Christine G\"{u}nther\and Frank Holzwarth\and Pia Maria Karbach \and\\
%Anna Kramer\and Erika
%Siebert-Cole}
%
\authorrunning{Explaing MOEAs, SSBSE'15}
% (feature abused for this document to repeat the title also on left hand pages)

% the affiliations are given next; don't give your e-mail address
% unless you accept that it will be published
\institute{Institution suppressed for blind review}

%
% NB: a more complex sample for affiliations and the mapping to the
% corresponding authors can be found in the file "llncs.dem"
% (search for the string "\mainmatter" where a contribution starts).
% "llncs.dem" accompanies the document class "llncs.cls".
%
 
\maketitle


\begin{abstract}
CT0 is very fast  algorithm for finding trade-offs in multi-objective problems.
A human inspecting those explanations 
can quickly infer changes
that can improve their situation. 
This paper evaluates those explanations using data
generated from   (a) the POM3 model of agile selection
of tasks; (b) four COCOMO-suite predictors for effort, months, defects and risk.
CT0 ran orders of magnitude faster than standard
optimizers  (e.g. 3 seconds vs 150 seconds).
Also, the  generated 
explanations were as effective for optimization
as the results of standard multi-objective
optimizers (NSGA-II and SPEA2). 

Based on this study, we recommend CT0 
when some succinct summary has to be rapidly generated (e.g.  in some interactive
design meeting). CT0 could also be useful as post-processor
to other optimizers (to generate succinct explanations of their
conclusions) or as a
optimizer to other optimizers (by constraining those other optimizers
to only search the regions recommended by CT0).

\keywords{Software engineering, explanation, optimization, multi-objective.}
\end{abstract}





\begin{myepigraph}
``If you cannot- in the long run- tell  everyone what \\
 you have been doing, your  doing has been worthless.''\\
 {\em-- Erwin Schrodinger}

\end{myepigraph}

\section{Introduction}
Explaining and the results of
multi-objective optimization to a user
can be problematic.
A typical run of a multi-objective optimizer
can process thousands to millions of examples.
It is an overwhelming task for humans to
certify the correctness of conclusions generated
from so many results. Verrappa and Leiter warn that
\begin{quote}
``..for industrial problems, these algorithms generate
(many) solutions, which makes the tasks of
understanding them and selecting one among them
difficult and time consuming''~\cite{veer11}.
\end{quote}
Even if explanations are constrained to
 (say) just a few hundred examples taken from the Pareto
frontier, this can still confuse the user.
 Valerdi notes that it can take days for
panels of human experts to rigorously review even a few dozen
examples~\cite{valerdi11}.  
For example, once had a 
client who disputed the results of our  analysis.
They
demanded to  audit the reasoning but
 when we delivered the 
of candidate solutions on the Pareto frontier,
they were overwhelmed by
the amount of information.  Flustered,
the client discounted the  analysis
and rejected our conclusions. From this experience, we learned that
to better support decision making in SBSE, we must better explain
SBSE results.

Other researchers have recognized the importance
of explanation and is known to be a key factor in selecting algorithms.
For example, in the field of machine learning,
``each time one of our favorite 
approaches has been applied in industry, each time the
comprehensibility of the results, though ill-defined, has
been a decisive factor of choice over an approach by pure
statistical means, or by neural networks.''~\cite{ag98}.
Analogous terms to explainability  in that community 
are ``comprehensibility'',
``interpretability''~\cite{maimon05} or ``understandability''~\cite{allahyari:user-oriented}.

In spite of the importance attributed to the subject,
explanation has not been extensively investigated in the context of SBSE.
One of the few papers that does is that of 
 Veerappa and Lieter~\cite{veerappa11} who
clustered examples from the Pareto
frontier (examples generated from a goal graph representation of requirements
for London ambulance services). In this approach,
``instead of having to inspect a large
number of individual solutions, (users) can look at a
much smaller number of groups of related solutions,
and focus their attention on the important
characteristics of the group rather than the
particularities of their individual solutions''~\cite{veerappa11}. 

XXXX

While an insightful study, we are concerned with
three issues about the Veerappa and Lieter study: (a)~the complexity
of clustering; (b)~erroneous conclusions could be generated from the users 
inspection of the clusters; (c)~introduced by users
incorrectly evaluation the value of generated recommendations.
 Veerappa and Lieter did not evaluate the effects
of the recommendations that could be generated by users browsing their
clusters. 
Also, their method could suffer from scalability issues since it
a post-processor
to a clustering algorithm (clustering is a slow process  requiring
 say, $O(N^2)$ comparisons
for the greedy agglomerate clustering algorithm used in that paper~\cite{koc11b}).

Accordingly, in this paper, when:
\be
\item Cluster using a near-linear time algorithm;
\item Then, when we infer some recommendations from the clusters,
we impose those recommendation back onto the model inputs in order to generate
more outputs. 
\ee
As a starting point in this exploration of explanation,
it is important to distinguish between the
(1)~problem of explaining the output of an
multi-objective optimizer (discussed in this paper);
from the more complex problem of (2)~explaining how
that output was generated.  To put that in a more
colloquial form, we seek to explain eggs, but not
the chicken.

Next, a definition of  ``explanation'' is required such that:
\be
\item An explanation system can be designed;
\item It is possible to distinguish a  ``good'' for a ``bad'' explanation.
\ee
In the SE literature,
the general consensus in
software engineering is that ``good'' explanations
are succinct explanations.  

Yet MOEAs fail on that
criteria. XXX

Cognitive science theory argues that
there is more to ``explaining'' something that just
showing it succinctly. According to Kelly's personal
construct theory (PCT) humans explain things via
``constructs'' that distinguish sets of examples~\cite{kelly55}.
So, for Kelly, human explanations are not about
``things'' in isolation but rather the {\em
differences between groups of things}. In data mining, finding
differences between things is called {\em contrast set learning}~\cite{webb09}.
Previously, work on
constrast learning for single goal SE problems
 found that very succinct contrast sets could be generated by 
\bi
\item Building a decision tree to separate the different outcomes;
\item Identifying leaves containing desired outcome $X$ and undesired outcome $Y$;
\item Querying that tree to find branches $B_x$ and $B_y$ that lead to
$X,Y$.
\item Computing  $B_x - B_y$ which   selects/rejects for
desired/undesired outcomes.
\ei
In one spectacularly successful demonstration of this technique~\cite{me03c}, it was found decision trees with 6,000 nodes had much
superfluous information that was not useful
for  distinguishing
desired and undesired outcomes.   
Using contrast set learning, the data that generated those
decisions trees generated
one
contrast   with only four variables in each (and when
applied to test data, that contrast
e was successful
at pruning away all the undesired outcomes). Other studies
with other data sets~\cite{me07} 
confirmed the {\bf
the law of tiny constrasts}:  {\em 
the minimal constrast set between things is usually much smaller
than a complete description of those things.}


Other  work by Leake characterized explaination as

Current MOEA algorithms are ``instance-based methods'' that return
specific examples that perform ``best'' with respect to the multiple goals.
The number of examples generated in this way can be overwhelming.

If a user wants to learn general principles from those examples,
some secondary {\em explanation} process is required to group and generalize those
examples.
For example,  Veerappa and Lieter~\cite{veerappa11} clustering examples from the Pareto
frontier so users (at a minimum) need only browse the centroids of each clusters).



GAs flat vectors, not the trees explored by by ()say) Gouse et al.

Goals is performance just as good but explain better

One caveat before beginning: if the audience for the
results of optimization are not human beings, then
perhaps an explanation systems is not required. For
example, Petke, Harman, Langdon, \&
Weimer~\cite{petke14} use evolutionary methods to
rewrite code such that the new code executes
faster. The audience for the rewritten code is a
compiler. Such compilers do not argue or and ask
questions about the code they are given to process.
Hence, that rewrite system does not necessary need
an explanation system.  That said, a succinct and
useful description of the difference between passing
and failing runs of the rewrite system could be
useful when (e.g.) a human is trying to debug that
code rewrite system.

Yet another model of ``explanation'' not explored
here is the ``surprise modeling'' approach
recommended by Voinea\&Tulea~\cite{voinea07} and
others including Horvitz~\cite{horvitz05}. In that
approach, (a)~some background knowledge
(e.g. summaries of prior actions by users) is used
to determine ``normal'' behavior; (b)~users are only
presented results that deviated from normal
expectations. In analogous research,
Koegh~\cite{keogh05} argues that {\em time series
  discords} (infrequent sequential events in a times
series) are a useful way to summarize reports from
complex temporal streams. The premise of surprise
modeling and reporting discords is that ``rare
events need to be explored''.  We do not dispute the
importance of exploring such outliers.  On the other
hand, when forming policies for software projects,
we need treatments that are well supported by the
data. Hence, our contrast sets report changes in the
data that, in our data, were {\em frequently} seen to
lead to change.

Another potential issue with CT0 is
correlation-vs-causation conflation. The issue here
is that contrast sets will be useless if they
report spurious correlations and not true causal
effects.  Proving that some effect is truly causal
is a non-trivial task.  The standard Hall criteria
for causal effects~\cite{paul13} is so strict that,
outside of highly controlled lab conditions, it
rarely accepts that any effect is causal.  Hence, in
software engineering, when researchers talk of
causality~\cite{couto14,zheng14z,huber09,bhat!icse12}
they use Granger's ``predictive causality'';
i.e. causality is the ability of predicting
values seen in the future from values seen in the
past.  Elsewhere, Granger causality has been adapted
to data mining by organizing cross-validations such
that the test sets contain data collected at a later
time than the training sets~\cite{me11f}.  In this
paper, we adapt Granger casualty to search-based
methods by testing recommendations learned from $M$
simulations on a subsequent round of $N$ new
simulations.  Those recommendations satisfy Granger
causality when the subsequent round of $N$
simulations are changed in a manner predicted by the
recommendations gleaned from the original $M$
simulations.

``Data farming'' is a technique used extensively by the
U.S. Military~\cite{meyer04}.
Data farming builds a ``landscape''
of output that can be analyzed for trends, anomalies, and insights in
multiple parameter dimensions.  
In  a recent review of search-based and data mining methids in SE,
we found numerous examples
of data farming~\cite{strickland03,Myrtveit,Shepperd01,pearce99,vanlamsweerde98integrating,chung00,me03j,heaven11,rodriguez11,jian09}.

In theory. Once a project manager can view their project on the landscape,
they can use this visualization to determine

We come to this work after attending a recent seminar at the US 
Department of Defence's Software Engineering Institute (SEI), Pittsburgh, USA.
That seminar reflected on how to best broadcast the lessons learned by SEI
to a very broad audience.

In the $21^{st}$ century, it is now impossible to manually browse very
large quantities of software project data.
For example, as of October 2012,
Mozilla Firefox had 800K reports on software projects.  While it is
now possible to automatically analyze such data with data miners, at
some stage a group of business users will have to convene to {\em
  interpret the results} (e.g., to decide if it is wise to deploy the
results as a defect reduction method within an organization).
These business  users are now demanding that data mining tools
be augmented with tools to support  business-level
interpretation of that data. For example,

at a recent panel on software analytics at ICSE'12,

industrial practitioners lamented the state of the art in data mining

and software engineering~\cite{menzies12a}. Panelists commented that

``prediction is all well and good, but what about decision

making?''. That is, these panelists are more interested in the interpretations

that follow the mining, rather than just  the mining.


You are strongly encouraged to use \LaTeXe{} for the
preparation of your camera-ready manuscript together with the
corresponding Springer class file \verb+llncs.cls+. Only if you use
\LaTeXe{} can hyperlinks be generated in the online version
of your manuscript.

The \LaTeX{} source of this instruction file for \LaTeX{} users may be used as
a template. This is located in the ``authors'' subdirectory in
\url{ftp://ftp.springer.de/pub/tex/latex/llncs/latex2e/instruct/} and
entitled \texttt{typeinst.tex}. Kindly
send the final and checked source and PDF files of your paper to the
Contact Volume Editor. This is usually one of the organizers of the
conference. You should make sure that the \LaTeX{} and the PDF files are
identical and correct and that only one version of your paper is sent.
It is not possible to update files at a later stage. Please note that we
do not need the printed paper.

We would like to draw your attention to the fact that it is not possible
to modify a paper in any way, once it has been published. This applies 
to both the printed book and the online version of the publication. 
Every detail, including the order of the names of the authors, should 
be checked before the paper is sent to the Volume Editors.

\subsection{Checking the PDF File}

Kindly assure that the Contact Volume Editor is given the name and email
address of the contact author for your paper. The Contact Volume Editor
uses these details to compile a list for our production department at
SPS in India. Once the files have been worked upon, SPS sends a copy of
the final pdf of each paper to its contact author. The contact author is
asked to check through the final pdf to make sure that no errors have
crept in during the transfer or preparation of the files. This should
not be seen as an opportunity to update or copyedit the papers, which is
not possible due to time constraints. Only errors introduced during the
preparation of the files will be corrected.

This round of checking takes place about two weeks after the files have
been sent to the Editorial by the Contact Volume Editor, i.e., roughly
seven weeks before the start of the conference for conference
proceedings, or seven weeks before the volume leaves the printer's, for
post-proceedings. If SPS does not receive a reply from a particular
contact author, within the timeframe given, then it is presumed that the
author has found no errors in the paper. The tight publication schedule
of LNCS does not allow SPS to send reminders or search for alternative
email addresses on the Internet.

In some cases, it is the Contact Volume Editor that checks all the final
pdfs. In such cases, the authors are not involved in the checking phase.

\subsection{Additional Information Required by the Volume Editor}

If you have more than one surname, please make sure that the Volume Editor
knows how you are to be listed in the author index.

\subsection{Copyright Forms}

The copyright form may be downloaded from the ``For Authors"
(Information for LNCS Authors)
section of the LNCS Website: \texttt{www.springer.com/lncs}.
Please send your signed copyright
form to the Contact Volume Editor, either as a scanned pdf or by fax or
by courier. One author may sign on behalf of all of the other authors of a particular
paper. Digital signatures are acceptable.

\section{Related Work}

Sayyad

GALE




\section{Paper Preparation}

Springer
provides you with a complete integrated \LaTeX{} document class (\texttt{llncs.cls})
for multi-author books such as those in the LNCS series.
Papers not complying with the LNCS style will be reformatted. This can
lead to an increase in the overall number of pages. We would therefore
urge you not to squash your paper.

Please always cancel any superfluous definitions that are
not actually used in your text. If you do not, these may conflict with
the definitions of the macro package, causing changes in the structure
of the text and leading to numerous mistakes in the proofs.

If you wonder what \LaTeX{} is and where it can be obtained, see the
``\textit{LaTeX project site}'' (\url{http://www.latex-project.org})
and especially the webpage ``\textit{How to get it}''
(\url{http://www.latex-project.org/ftp.html}) respectively.

When you use \LaTeX\ together with our document class file,
\texttt{llncs.cls},
your text is typeset automatically in Computer Modern Roman (CM) fonts.
Please do
\emph{not} change the preset fonts. If you have to use fonts other
than the preset fonts, kindly submit these with your files.

Please use the commands \verb+\label+ and \verb+\ref+ for
cross-references and the commands \verb+\bibitem+ and \verb+\cite+ for
references to the bibliography, to enable us to create hyperlinks at
these places.

For preparing your figures electronically and integrating them into
your source file we recommend using the standard \LaTeX{} \verb+graphics+ or
\verb+graphicx+ package. These provide the \verb+\includegraphics+ command.
In general, please refrain from using the \verb+\special+ command.

Remember to submit any further style files and
fonts you have used together with your source files.

\subsubsection{Headings.}

Headings should be capitalized
(i.e., nouns, verbs, and all other words
except articles, prepositions, and conjunctions should be set with an
initial capital) and should,
with the exception of the title, be aligned to the left.
Words joined by a hyphen are subject to a special rule. If the first
word can stand alone, the second word should be capitalized.

Here are some examples of headings: ``Criteria to Disprove
Context-Freeness of Collage Language", ``On Correcting the Intrusion of
Tracing Non-deterministic Programs by Software", ``A User-Friendly and
Extendable Data Distribution System", ``Multi-flip Networks:
Parallelizing GenSAT", ``Self-determinations of Man".

\subsubsection{Lemmas, Propositions, and Theorems.}

The numbers accorded to lemmas, propositions, and theorems, etc. should
appear in consecutive order, starting with Lemma 1, and not, for
example, with Lemma 11.

\subsection{Figures}

For \LaTeX\ users, we recommend using the \emph{graphics} or \emph{graphicx}
package and the \verb+\includegraphics+ command.

Please check that the lines in line drawings are not
interrupted and are of a constant width. Grids and details within the
figures must be clearly legible and may not be written one on top of
the other. Line drawings should have a resolution of at least 800 dpi
(preferably 1200 dpi). The lettering in figures should have a height of
2~mm (10-point type). Figures should be numbered and should have a
caption which should always be positioned \emph{under} the figures, in
contrast to the caption belonging to a table, which should always appear
\emph{above} the table; this is simply achieved as matter of sequence in
your source.

Please center the figures or your tabular material by using the \verb+\centering+
declaration. Short captions are centered by default between the margins
and typeset in 9-point type (Fig.~\ref{fig:example} shows an example).
The distance between text and figure is preset to be about 8~mm, the
distance between figure and caption about 6~mm.

To ensure that the reproduction of your illustrations is of a reasonable
quality, we advise against the use of shading. The contrast should be as
pronounced as possible.

If screenshots are necessary, please make sure that you are happy with
the print quality before you send the files.
 

Please define figures (and tables) as floating objects. Please avoid
using optional location parameters like ``\verb+[h]+" for ``here".

\paragraph{Remark 1.}

In the printed volumes, illustrations are generally black and white
(halftones), and only in exceptional cases, and if the author is
prepared to cover the extra cost for color reproduction, are colored
pictures accepted. Colored pictures are welcome in the electronic
version free of charge. If you send colored figures that are to be
printed in black and white, please make sure that they really are
legible in black and white. Some colors as well as the contrast of
converted colors show up very poorly when printed in black and white.

\subsection{Formulas}

Displayed equations or formulas are centered and set on a separate
line (with an extra line or halfline space above and below). Displayed
expressions should be numbered for reference. The numbers should be
consecutive within each section or within the contribution,
with numbers enclosed in parentheses and set on the right margin --
which is the default if you use the \emph{equation} environment, e.g.,
\begin{equation}
  \psi (u) = \int_{o}^{T} \left[\frac{1}{2}
  \left(\Lambda_{o}^{-1} u,u\right) + N^{\ast} (-u)\right] dt \;  .
\end{equation}

Equations should be punctuated in the same way as ordinary
text but with a small space before the end punctuation mark.

\subsection{Footnotes}

The superscript numeral used to refer to a footnote appears in the text
either directly after the word to be discussed or -- in relation to a
phrase or a sentence -- following the punctuation sign (comma,
semicolon, or period). Footnotes should appear at the bottom of
the
normal text area, with a line of about 2~cm set
immediately above them.\footnote{The footnote numeral is set flush left
and the text follows with the usual word spacing.}

\subsection{Program Code}

Program listings or program commands in the text are normally set in
typewriter font, e.g., CMTT10 or Courier.

\medskip

\noindent
{\it Example of a Computer Program}
\begin{verbatim}
program Inflation (Output)
  {Assuming annual inflation rates of 7%, 8%, and 10%,...
   years};
   const
     MaxYears = 10;
   var
     Year: 0..MaxYears;
     Factor1, Factor2, Factor3: Real;
   begin
     Year := 0;
     Factor1 := 1.0; Factor2 := 1.0; Factor3 := 1.0;
     WriteLn('Year  7% 8% 10%'); WriteLn;
     repeat
       Year := Year + 1;
       Factor1 := Factor1 * 1.07;
       Factor2 := Factor2 * 1.08;
       Factor3 := Factor3 * 1.10;
       WriteLn(Year:5,Factor1:7:3,Factor2:7:3,Factor3:7:3)
     until Year = MaxYears
end.
\end{verbatim}
%
\noindent
{\small (Example from Jensen K., Wirth N. (1991) Pascal user manual and
report. Springer, New York)}

\subsection{Citations}

For citations in the text please use
square brackets and consecutive numbers: \cite{jour}, \cite{lncschap},
\cite{proceeding1} -- provided automatically
by \LaTeX 's \verb|\cite| \dots\verb|\bibitem| mechanism.

\subsection{Page Numbering and Running Heads}

There is no need to include page numbers. If your paper title is too
long to serve as a running head, it will be shortened. Your suggestion
as to how to shorten it would be most welcome.

\section{LNCS Online}

The online version of the volume will be available in LNCS Online.
Members of institutes subscribing to the Lecture Notes in Computer
Science series have access to all the pdfs of all the online
publications. Non-subscribers can only read as far as the abstracts. If
they try to go beyond this point, they are automatically asked, whether
they would like to order the pdf, and are given instructions as to how
to do so.

Please note that, if your email address is given in your paper,
it will also be included in the meta data of the online version.

\section{BibTeX Entries}

The correct BibTeX entries for the Lecture Notes in Computer Science
volumes can be found at the following Website shortly after the
publication of the book:
\url{http://www.informatik.uni-trier.de/~ley/db/journals/lncs.html}

\subsubsection*{Acknowledgments.} The heading should be treated as a
subsubsection heading and should not be assigned a number.

\section{The References Section}\label{references}

In order to permit cross referencing within LNCS-Online, and eventually
between different publishers and their online databases, LNCS will,
from now on, be standardizing the format of the references. This new
feature will increase the visibility of publications and facilitate
academic research considerably. Please base your references on the
examples below. References that don't adhere to this style will be
reformatted by Springer. You should therefore check your references
thoroughly when you receive the final pdf of your paper.
The reference section must be complete. You may not omit references.
Instructions as to where to find a fuller version of the references are
not permissible.

We only accept references written using the latin alphabet. If the title 
of the book you are referring to is in Russian or Chinese, then please write 
(in Russian) or (in Chinese) at the end of the transcript or translation 
of the title.

The following section shows a sample reference list with entries for
journal articles \cite{jour}, an LNCS chapter \cite{lncschap}, a book
\cite{book}, proceedings without editors \cite{proceeding1} and
\cite{proceeding2}, as well as a URL \cite{url}.
Please note that proceedings published in LNCS are not cited with their
full titles, but with their acronyms!


{\scriptsize
\bibliographystyle{abbrv}


%\let\oldbibliography\thebibliography
%\renewcommand{\thebibliography}[1]{\oldbibliography{#1}
%\setlength{\itemsep}{0pt}} %Reducing spacing in the bibliography.
\bibliography{refs}}
\end{document}
